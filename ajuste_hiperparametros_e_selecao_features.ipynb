{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ajuste de Hiperparâmetros e Seleção de Features\n",
        "\n",
        "Este notebook demonstra como aplicar técnicas de otimização de modelos de machine learning:\n",
        "\n",
        "1. **Grid Search** para ajuste de hiperparâmetros no modelo de árvore de decisão para classificação (California Housing)\n",
        "2. **Seleção de Features** para identificar características importantes na previsão de diabetes (Pima Indians Diabetes)\n",
        "\n",
        "## Objetivos:\n",
        "- Aprender a usar Grid Search para encontrar os melhores hiperparâmetros\n",
        "- Entender como identificar as features mais relevantes\n",
        "- Comparar o desempenho antes e depois da otimização\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, mutual_info_classif, mutual_info_regression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuração para visualizações\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 1: Grid Search para Classificação - California Housing\n",
        "\n",
        "Vamos trabalhar com o dataset California Housing, mas transformando-o em um problema de classificação criando categorias de preços de casas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregando o dataset California Housing\n",
        "california_housing = fetch_california_housing()\n",
        "X_california = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "y_california = california_housing.target\n",
        "\n",
        "print(\"Dataset California Housing:\")\n",
        "print(f\"Forma dos dados: {X_california.shape}\")\n",
        "print(f\"Features: {list(X_california.columns)}\")\n",
        "print(f\"Primeiras linhas:\")\n",
        "print(X_california.head())\n",
        "\n",
        "# Transformando em problema de classificação\n",
        "# Criando categorias baseadas nos quartis dos preços\n",
        "y_california_cat = pd.cut(y_california, bins=4, labels=['Muito Baixo', 'Baixo', 'Alto', 'Muito Alto'])\n",
        "print(f\"\\nDistribuição das categorias de preço:\")\n",
        "print(y_california_cat.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparando os dados para classificação\n",
        "X_train_cal, X_test_cal, y_train_cal, y_test_cal = train_test_split(\n",
        "    X_california, y_california_cat, test_size=0.2, random_state=42, stratify=y_california_cat\n",
        ")\n",
        "\n",
        "print(f\"Conjunto de treino: {X_train_cal.shape}\")\n",
        "print(f\"Conjunto de teste: {X_test_cal.shape}\")\n",
        "\n",
        "# Modelo base (sem ajuste de hiperparâmetros)\n",
        "dt_base = DecisionTreeClassifier(random_state=42)\n",
        "dt_base.fit(X_train_cal, y_train_cal)\n",
        "\n",
        "# Avaliando o modelo base\n",
        "y_pred_base = dt_base.predict(X_test_cal)\n",
        "accuracy_base = dt_base.score(X_test_cal, y_test_cal)\n",
        "\n",
        "print(f\"\\n=== MODELO BASE (Árvore de Decisão) ===\")\n",
        "print(f\"Acurácia: {accuracy_base:.4f}\")\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test_cal, y_pred_base))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aplicando Grid Search para Otimização de Hiperparâmetros\n",
        "\n",
        "Agora vamos usar Grid Search para encontrar os melhores hiperparâmetros para nossa árvore de decisão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definindo o grid de hiperparâmetros para testar\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "print(\"Grid de hiperparâmetros definido:\")\n",
        "for param, values in param_grid.items():\n",
        "    print(f\"{param}: {values}\")\n",
        "\n",
        "# Criando o modelo para Grid Search\n",
        "dt_grid = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Aplicando Grid Search com validação cruzada\n",
        "print(f\"\\nIniciando Grid Search...\")\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=dt_grid,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,  # 5-fold cross validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,  # Usar todos os cores disponíveis\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinando o modelo com Grid Search\n",
        "grid_search.fit(X_train_cal, y_train_cal)\n",
        "\n",
        "print(f\"\\nGrid Search concluído!\")\n",
        "print(f\"Melhores parâmetros encontrados:\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"Melhor score (CV): {grid_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Avaliando o modelo otimizado\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_optimized = best_model.predict(X_test_cal)\n",
        "accuracy_optimized = best_model.score(X_test_cal, y_test_cal)\n",
        "\n",
        "print(f\"\\n=== MODELO OTIMIZADO (Grid Search) ===\")\n",
        "print(f\"Acurácia: {accuracy_optimized:.4f}\")\n",
        "print(f\"Melhoria: {accuracy_optimized - accuracy_base:.4f}\")\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test_cal, y_pred_optimized))\n",
        "\n",
        "# Matriz de confusão\n",
        "plt.figure(figsize=(10, 6))\n",
        "cm = confusion_matrix(y_test_cal, y_pred_optimized)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=best_model.classes_, yticklabels=best_model.classes_)\n",
        "plt.title('Matriz de Confusão - Modelo Otimizado')\n",
        "plt.ylabel('Valores Reais')\n",
        "plt.xlabel('Valores Previstos')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando a importância das features no modelo otimizado\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_california.columns,\n",
        "    'importance': best_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Importância das Features - Modelo Otimizado')\n",
        "plt.xlabel('Importância')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Importância das features:\")\n",
        "print(feature_importance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 2: Seleção de Features para Regressão - Pima Indians Diabetes\n",
        "\n",
        "Agora vamos trabalhar com o dataset Pima Indians Diabetes para demonstrar técnicas de seleção de features em um problema de regressão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregando o dataset Pima Indians Diabetes\n",
        "# URL do dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
        "                'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "\n",
        "try:\n",
        "    # Tentando carregar do URL\n",
        "    df_pima = pd.read_csv(url, names=column_names)\n",
        "    print(\"Dataset carregado com sucesso do URL!\")\n",
        "except:\n",
        "    # Se não conseguir carregar do URL, criamos dados sintéticos baseados no dataset original\n",
        "    print(\"Criando dados sintéticos baseados no dataset Pima Indians Diabetes...\")\n",
        "    np.random.seed(42)\n",
        "    n_samples = 768\n",
        "    \n",
        "    # Gerando dados sintéticos baseados nas características do dataset original\n",
        "    df_pima = pd.DataFrame({\n",
        "        'Pregnancies': np.random.poisson(3.8, n_samples),\n",
        "        'Glucose': np.random.normal(120.9, 32.0, n_samples),\n",
        "        'BloodPressure': np.random.normal(69.1, 19.4, n_samples),\n",
        "        'SkinThickness': np.random.normal(20.5, 16.0, n_samples),\n",
        "        'Insulin': np.random.normal(79.8, 115.2, n_samples),\n",
        "        'BMI': np.random.normal(32.0, 7.9, n_samples),\n",
        "        'DiabetesPedigreeFunction': np.random.exponential(0.5, n_samples),\n",
        "        'Age': np.random.normal(33.2, 11.8, n_samples),\n",
        "        'Outcome': np.random.binomial(1, 0.35, n_samples)\n",
        "    })\n",
        "    \n",
        "    # Ajustando valores negativos\n",
        "    df_pima['Glucose'] = np.maximum(df_pima['Glucose'], 0)\n",
        "    df_pima['BloodPressure'] = np.maximum(df_pima['BloodPressure'], 0)\n",
        "    df_pima['SkinThickness'] = np.maximum(df_pima['SkinThickness'], 0)\n",
        "    df_pima['Insulin'] = np.maximum(df_pima['Insulin'], 0)\n",
        "    df_pima['BMI'] = np.maximum(df_pima['BMI'], 0)\n",
        "    df_pima['Age'] = np.maximum(df_pima['Age'], 0)\n",
        "\n",
        "print(f\"\\nDataset Pima Indians Diabetes:\")\n",
        "print(f\"Forma dos dados: {df_pima.shape}\")\n",
        "print(f\"Primeiras linhas:\")\n",
        "print(df_pima.head())\n",
        "\n",
        "print(f\"\\nInformações do dataset:\")\n",
        "print(df_pima.info())\n",
        "\n",
        "print(f\"\\nEstatísticas descritivas:\")\n",
        "print(df_pima.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformando em problema de regressão\n",
        "# Vamos usar as features para prever o valor de Glucose (como se fosse um problema de regressão)\n",
        "X_pima = df_pima.drop(['Outcome', 'Glucose'], axis=1)  # Removendo Outcome e Glucose\n",
        "y_pima = df_pima['Glucose']  # Usando Glucose como variável alvo\n",
        "\n",
        "print(f\"Features para regressão: {list(X_pima.columns)}\")\n",
        "print(f\"Variável alvo: Glucose\")\n",
        "print(f\"Forma dos dados: X={X_pima.shape}, y={y_pima.shape}\")\n",
        "\n",
        "# Dividindo os dados\n",
        "X_train_pima, X_test_pima, y_train_pima, y_test_pima = train_test_split(\n",
        "    X_pima, y_pima, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nConjunto de treino: {X_train_pima.shape}\")\n",
        "print(f\"Conjunto de teste: {X_test_pima.shape}\")\n",
        "\n",
        "# Modelo base (sem seleção de features)\n",
        "rf_base = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "rf_base.fit(X_train_pima, y_train_pima)\n",
        "\n",
        "# Avaliando o modelo base\n",
        "y_pred_base_pima = rf_base.predict(X_test_pima)\n",
        "mse_base = mean_squared_error(y_test_pima, y_pred_base_pima)\n",
        "r2_base = r2_score(y_test_pima, y_pred_base_pima)\n",
        "\n",
        "print(f\"\\n=== MODELO BASE (Random Forest) ===\")\n",
        "print(f\"MSE: {mse_base:.4f}\")\n",
        "print(f\"R²: {r2_base:.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mse_base):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aplicando Técnicas de Seleção de Features\n",
        "\n",
        "Vamos aplicar diferentes métodos de seleção de features para identificar as mais importantes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Seleção baseada em F-score (f_regression)\n",
        "f_selector = SelectKBest(score_func=f_regression, k=5)\n",
        "X_train_f = f_selector.fit_transform(X_train_pima, y_train_pima)\n",
        "X_test_f = f_selector.transform(X_test_pima)\n",
        "\n",
        "# Features selecionadas pelo F-score\n",
        "selected_features_f = X_pima.columns[f_selector.get_support()].tolist()\n",
        "f_scores = f_selector.scores_\n",
        "\n",
        "print(\"=== SELEÇÃO POR F-SCORE ===\")\n",
        "print(f\"Features selecionadas: {selected_features_f}\")\n",
        "print(f\"Scores F:\")\n",
        "for feature, score in zip(X_pima.columns, f_scores):\n",
        "    print(f\"  {feature}: {score:.4f}\")\n",
        "\n",
        "# 2. Seleção baseada em Mutual Information\n",
        "mi_selector = SelectKBest(score_func=mutual_info_regression, k=5)\n",
        "X_train_mi = mi_selector.fit_transform(X_train_pima, y_train_pima)\n",
        "X_test_mi = mi_selector.transform(X_test_pima)\n",
        "\n",
        "# Features selecionadas pelo Mutual Information\n",
        "selected_features_mi = X_pima.columns[mi_selector.get_support()].tolist()\n",
        "mi_scores = mi_selector.scores_\n",
        "\n",
        "print(f\"\\n=== SELEÇÃO POR MUTUAL INFORMATION ===\")\n",
        "print(f\"Features selecionadas: {selected_features_mi}\")\n",
        "print(f\"Scores MI:\")\n",
        "for feature, score in zip(X_pima.columns, mi_scores):\n",
        "    print(f\"  {feature}: {score:.4f}\")\n",
        "\n",
        "# 3. Seleção baseada na importância do Random Forest\n",
        "rf_importance = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "rf_importance.fit(X_train_pima, y_train_pima)\n",
        "\n",
        "feature_importance_rf = pd.DataFrame({\n",
        "    'feature': X_pima.columns,\n",
        "    'importance': rf_importance.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(f\"\\n=== IMPORTÂNCIA DO RANDOM FOREST ===\")\n",
        "print(\"Features ordenadas por importância:\")\n",
        "print(feature_importance_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparando modelos com diferentes seleções de features\n",
        "\n",
        "# Modelo com features selecionadas por F-score\n",
        "rf_f = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "rf_f.fit(X_train_f, y_train_pima)\n",
        "y_pred_f = rf_f.predict(X_test_f)\n",
        "mse_f = mean_squared_error(y_test_pima, y_pred_f)\n",
        "r2_f = r2_score(y_test_pima, y_pred_f)\n",
        "\n",
        "# Modelo com features selecionadas por Mutual Information\n",
        "rf_mi = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "rf_mi.fit(X_train_mi, y_train_pima)\n",
        "y_pred_mi = rf_mi.predict(X_test_mi)\n",
        "mse_mi = mean_squared_error(y_test_pima, y_pred_mi)\n",
        "r2_mi = r2_score(y_test_pima, y_pred_mi)\n",
        "\n",
        "# Modelo com top 5 features mais importantes do Random Forest\n",
        "top_5_features = feature_importance_rf.head(5)['feature'].tolist()\n",
        "X_train_top5 = X_train_pima[top_5_features]\n",
        "X_test_top5 = X_test_pima[top_5_features]\n",
        "\n",
        "rf_top5 = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "rf_top5.fit(X_train_top5, y_train_pima)\n",
        "y_pred_top5 = rf_top5.predict(X_test_top5)\n",
        "mse_top5 = mean_squared_error(y_test_pima, y_pred_top5)\n",
        "r2_top5 = r2_score(y_test_pima, y_pred_top5)\n",
        "\n",
        "print(\"=== COMPARAÇÃO DE MODELOS ===\")\n",
        "print(f\"{'Modelo':<25} {'MSE':<10} {'R²':<10} {'RMSE':<10}\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Base (todas features)':<25} {mse_base:<10.4f} {r2_base:<10.4f} {np.sqrt(mse_base):<10.4f}\")\n",
        "print(f\"{'F-score (top 5)':<25} {mse_f:<10.4f} {r2_f:<10.4f} {np.sqrt(mse_f):<10.4f}\")\n",
        "print(f\"{'Mutual Info (top 5)':<25} {mse_mi:<10.4f} {r2_mi:<10.4f} {np.sqrt(mse_mi):<10.4f}\")\n",
        "print(f\"{'RF Importance (top 5)':<25} {mse_top5:<10.4f} {r2_top5:<10.4f} {np.sqrt(mse_top5):<10.4f}\")\n",
        "\n",
        "print(f\"\\nTop 5 features por importância (Random Forest):\")\n",
        "print(top_5_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizações das análises de seleção de features\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. F-scores\n",
        "axes[0, 0].bar(X_pima.columns, f_scores)\n",
        "axes[0, 0].set_title('F-Scores para Seleção de Features')\n",
        "axes[0, 0].set_ylabel('F-Score')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 2. Mutual Information Scores\n",
        "axes[0, 1].bar(X_pima.columns, mi_scores)\n",
        "axes[0, 1].set_title('Mutual Information Scores')\n",
        "axes[0, 1].set_ylabel('MI Score')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 3. Feature Importance (Random Forest)\n",
        "axes[1, 0].barh(feature_importance_rf['feature'], feature_importance_rf['importance'])\n",
        "axes[1, 0].set_title('Feature Importance (Random Forest)')\n",
        "axes[1, 0].set_xlabel('Importance')\n",
        "\n",
        "# 4. Comparação de Performance\n",
        "models = ['Base', 'F-score', 'MI', 'RF Top5']\n",
        "r2_scores = [r2_base, r2_f, r2_mi, r2_top5]\n",
        "axes[1, 1].bar(models, r2_scores)\n",
        "axes[1, 1].set_title('Comparação de R² Score')\n",
        "axes[1, 1].set_ylabel('R² Score')\n",
        "axes[1, 1].set_ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análise de Correlação entre Features\n",
        "\n",
        "Vamos analisar a correlação entre as features para entender melhor as relações no dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise de correlação\n",
        "correlation_data = X_pima.copy()\n",
        "correlation_data['Glucose'] = y_pima  # Adicionando a variável alvo\n",
        "\n",
        "correlation_matrix = correlation_data.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, fmt='.3f')\n",
        "plt.title('Matriz de Correlação - Features vs Glucose')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlação com a variável alvo (Glucose)\n",
        "glucose_corr = correlation_matrix['Glucose'].drop('Glucose').sort_values(key=abs, ascending=False)\n",
        "print(\"Correlação das features com Glucose (variável alvo):\")\n",
        "print(glucose_corr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo e Insights\n",
        "\n",
        "### Grid Search para Classificação (California Housing)\n",
        "\n",
        "**O que aprendemos:**\n",
        "- O Grid Search testou sistematicamente diferentes combinações de hiperparâmetros\n",
        "- Encontrou a melhor configuração através de validação cruzada\n",
        "- Melhorou o desempenho do modelo comparado aos parâmetros padrão\n",
        "\n",
        "**Hiperparâmetros testados:**\n",
        "- `max_depth`: Profundidade máxima da árvore\n",
        "- `min_samples_split`: Número mínimo de amostras para dividir um nó\n",
        "- `min_samples_leaf`: Número mínimo de amostras em uma folha\n",
        "- `criterion`: Critério para medir a qualidade de uma divisão\n",
        "- `max_features`: Número de features a considerar para a melhor divisão\n",
        "\n",
        "### Seleção de Features para Regressão (Pima Indians Diabetes)\n",
        "\n",
        "**Métodos aplicados:**\n",
        "1. **F-Score**: Mede a relação linear entre features e variável alvo\n",
        "2. **Mutual Information**: Captura dependências não-lineares\n",
        "3. **Feature Importance (Random Forest)**: Baseado na redução de impureza\n",
        "\n",
        "**Insights importantes:**\n",
        "- Diferentes métodos podem selecionar features diferentes\n",
        "- A seleção de features pode melhorar ou manter a performance com menos variáveis\n",
        "- É importante comparar múltiplos métodos para uma análise robusta\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "Para continuar explorando:\n",
        "1. Testar outros algoritmos de seleção de features\n",
        "2. Aplicar técnicas de redução de dimensionalidade (PCA, LDA)\n",
        "3. Experimentar com diferentes números de features selecionadas\n",
        "4. Usar validação cruzada para uma avaliação mais robusta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Código adicional para experimentação\n",
        "\n",
        "# Função para testar diferentes números de features\n",
        "def test_feature_selection(n_features_list, X_train, X_test, y_train, y_test):\n",
        "    results = []\n",
        "    \n",
        "    for n_features in n_features_list:\n",
        "        # Seleção por F-score\n",
        "        selector = SelectKBest(score_func=f_regression, k=n_features)\n",
        "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "        X_test_selected = selector.transform(X_test)\n",
        "        \n",
        "        # Treinar modelo\n",
        "        model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "        model.fit(X_train_selected, y_train)\n",
        "        \n",
        "        # Avaliar\n",
        "        y_pred = model.predict(X_test_selected)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        \n",
        "        results.append({\n",
        "            'n_features': n_features,\n",
        "            'r2': r2,\n",
        "            'mse': mse,\n",
        "            'rmse': np.sqrt(mse)\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Testando diferentes números de features\n",
        "n_features_list = [1, 2, 3, 4, 5, 6, 7]\n",
        "results_df = test_feature_selection(n_features_list, X_train_pima, X_test_pima, \n",
        "                                   y_train_pima, y_test_pima)\n",
        "\n",
        "print(\"Resultados para diferentes números de features:\")\n",
        "print(results_df)\n",
        "\n",
        "# Visualizando os resultados\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(results_df['n_features'], results_df['r2'], 'o-')\n",
        "plt.xlabel('Número de Features')\n",
        "plt.ylabel('R² Score')\n",
        "plt.title('R² Score vs Número de Features')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(results_df['n_features'], results_df['rmse'], 'o-', color='red')\n",
        "plt.xlabel('Número de Features')\n",
        "plt.ylabel('RMSE')\n",
        "plt.title('RMSE vs Número de Features')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
