# Ajuste de HiperparÃ¢metros e SeleÃ§Ã£o de Features

Este projeto demonstra tÃ©cnicas avanÃ§adas de otimizaÃ§Ã£o de modelos de machine learning, incluindo **Grid Search** para ajuste de hiperparÃ¢metros e **SeleÃ§Ã£o de Features** para identificar as caracterÃ­sticas mais relevantes.

## ğŸ“‹ ConteÃºdo

### 1. Grid Search para ClassificaÃ§Ã£o
- **Dataset**: California Housing (transformado em problema de classificaÃ§Ã£o)
- **Modelo**: Ãrvore de DecisÃ£o
- **TÃ©cnica**: Grid Search com validaÃ§Ã£o cruzada
- **Objetivo**: Encontrar os melhores hiperparÃ¢metros para maximizar a acurÃ¡cia

### 2. SeleÃ§Ã£o de Features para RegressÃ£o
- **Dataset**: Pima Indians Diabetes (transformado em problema de regressÃ£o)
- **Modelo**: Random Forest
- **TÃ©cnicas**: F-Score, Mutual Information, Feature Importance
- **Objetivo**: Identificar as features mais importantes para previsÃ£o

## ğŸš€ Como Usar

### PrÃ©-requisitos
```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

### Executando o Notebook
1. Abra o arquivo `ajuste_hiperparametros_e_selecao_features.ipynb` no Google Colab
2. Execute todas as cÃ©lulas sequencialmente
3. Observe os resultados e visualizaÃ§Ãµes

## ğŸ“Š TÃ©cnicas Implementadas

### Grid Search
- **HiperparÃ¢metros testados**:
  - `max_depth`: [3, 5, 7, 10, None]
  - `min_samples_split`: [2, 5, 10, 20]
  - `min_samples_leaf`: [1, 2, 4, 8]
  - `criterion`: ['gini', 'entropy']
  - `max_features`: ['sqrt', 'log2', None]

### SeleÃ§Ã£o de Features
1. **F-Score**: Mede relaÃ§Ã£o linear entre features e variÃ¡vel alvo
2. **Mutual Information**: Captura dependÃªncias nÃ£o-lineares
3. **Feature Importance**: Baseado na reduÃ§Ã£o de impureza (Random Forest)

## ğŸ“ˆ Resultados Esperados

### ClassificaÃ§Ã£o (California Housing)
- ComparaÃ§Ã£o entre modelo base e otimizado
- Matriz de confusÃ£o
- ImportÃ¢ncia das features
- Melhoria na acurÃ¡cia

### RegressÃ£o (Pima Indians Diabetes)
- ComparaÃ§Ã£o de diferentes mÃ©todos de seleÃ§Ã£o
- AnÃ¡lise de correlaÃ§Ã£o entre features
- Performance com diferentes nÃºmeros de features
- VisualizaÃ§Ãµes comparativas

## ğŸ” Insights Principais

1. **Grid Search** pode melhorar significativamente o desempenho do modelo
2. **Diferentes mÃ©todos** de seleÃ§Ã£o de features podem identificar caracterÃ­sticas distintas
3. **SeleÃ§Ã£o de features** pode manter ou melhorar a performance com menos variÃ¡veis
4. **ValidaÃ§Ã£o cruzada** Ã© essencial para uma avaliaÃ§Ã£o robusta

## ğŸ“ Estrutura do Projeto

```
easynext_modelos_machine_learning/
â”œâ”€â”€ README.md
â””â”€â”€ ajuste_hiperparametros_e_selecao_features.ipynb
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**
- **Pandas**: ManipulaÃ§Ã£o de dados
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **Matplotlib/Seaborn**: VisualizaÃ§Ãµes
- **Scikit-learn**: Machine learning
- **Google Colab**: Ambiente de execuÃ§Ã£o

## ğŸ“š Conceitos Aprendidos

### Ajuste de HiperparÃ¢metros
- Como usar Grid Search
- ValidaÃ§Ã£o cruzada
- ComparaÃ§Ã£o de modelos
- InterpretaÃ§Ã£o de resultados

### SeleÃ§Ã£o de Features
- MÃ©todos estatÃ­sticos (F-Score)
- MÃ©todos baseados em informaÃ§Ã£o (Mutual Information)
- MÃ©todos baseados em Ã¡rvores (Feature Importance)
- AnÃ¡lise de correlaÃ§Ã£o

## ğŸ¯ PrÃ³ximos Passos

Para continuar explorando:
1. Testar outros algoritmos de seleÃ§Ã£o de features
2. Aplicar tÃ©cnicas de reduÃ§Ã£o de dimensionalidade (PCA, LDA)
3. Experimentar com diferentes nÃºmeros de features selecionadas
4. Usar validaÃ§Ã£o cruzada para uma avaliaÃ§Ã£o mais robusta
5. Implementar Random Search como alternativa ao Grid Search

## ğŸ“– ReferÃªncias

- [Scikit-learn Grid Search](https://scikit-learn.org/stable/modules/grid_search.html)
- [Feature Selection in Scikit-learn](https://scikit-learn.org/stable/modules/feature_selection.html)
- [California Housing Dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)
- [Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)

## ğŸ‘¥ ContribuiÃ§Ãµes

Este projeto foi desenvolvido como parte do curso de Machine Learning da EasyNext. Sinta-se Ã  vontade para sugerir melhorias ou adicionar novas funcionalidades!

---

**Desenvolvido com â¤ï¸ para o aprendizado de Machine Learning**
